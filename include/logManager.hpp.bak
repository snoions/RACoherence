#ifndef _LOG_BUFFER_H_
#define _LOG_BUFFER_H_

#include <atomic>
#include <array>
#include <cassert>
#include <cstdint>
#include <cstddef>
#include <iostream>
#include <mutex>

#include "MPMCQueue.hpp"
#include "config.hpp"
#include "logger.hpp"

constexpr size_t LOG_SIZE = 1ull << 6;
//LOG_BUF_SIZE must be power of 2
constexpr size_t LOG_BUF_SIZE = 1ull << 10;

extern thread_local unsigned node_id;

class LogManager;

class alignas(CACHE_LINE_SIZE) Log {
    friend LogManager;

    using Entry = uintptr_t;
    using Data = Entry[LOG_SIZE];
    using iterator = Entry *;
    using const_iterator = const Entry *;

    Data entries;
    size_t size = 0;
    bool is_rel = false;

public:

    inline bool write(uintptr_t cl_addr) {
        if (size == LOG_SIZE)
            return false;
        entries[size++] = cl_addr;
        return true;
    }

    bool is_release() {
        return is_rel;
    }

    const_iterator begin() const {
        return &entries[0];
    }

    const_iterator end() const {
        return &entries[size];
    }
};

class alignas(CACHE_LINE_SIZE) LogManager {
    // node-local allocator to reduce coherence messages between nodes

    // index into pub with a high parity bit
    using par_idx_t = size_t;

    struct alignas(CACHE_LINE_SIZE) aligned_par_idx_t {
        par_idx_t data;
    };

    struct alignas(CACHE_LINE_SIZE) aligned_mutex {
        std::mutex data;
    };

    mpmc_bounded_queue<Log *, LOG_BUF_SIZE> freelist;
    Log *pub[LOG_BUF_SIZE] = {};
    par_idx_t bound = flip(0);

    alignas(CACHE_LINE_SIZE)
    Log buf[LOG_BUF_SIZE];

    alignas(CACHE_LINE_SIZE)
    std::atomic<par_idx_t> tail {0};

    //TODO: pad to different cache lines
    alignas(CACHE_LINE_SIZE)
    std::atomic<par_idx_t> heads[NODE_COUNT];

    alignas(CACHE_LINE_SIZE)
    std::mutex head_mtxs[NODE_COUNT];

    alignas(CACHE_LINE_SIZE)
    std::mutex gc_mtx;

    alignas(CACHE_LINE_SIZE)
    std::mutex tail_mtx;

    inline par_idx_t next(par_idx_t idx) {
        return (idx+1) & ((LOG_BUF_SIZE << 1)-1);
    }
    inline par_idx_t flip(par_idx_t idx) {
        return idx ^ LOG_BUF_SIZE;
    }
    inline size_t get_idx(par_idx_t idx){
        return idx & (LOG_BUF_SIZE -1);
    }

    //TODO: check memory order
    inline void perform_gc() {
        par_idx_t new_b = LOG_BUF_SIZE*2;
        for (int i = 0; i < NODE_COUNT; i++) {
            if (i == node_id)
               continue;
            auto h = flip(heads[i].load(std::memory_order_relaxed));
            if (new_b == LOG_BUF_SIZE*2)
                new_b = h;
            else if (bound <= h && h < new_b)
                new_b = h;
            else if (h < new_b && new_b < bound)
                new_b = h;
            else if (new_b < bound && bound <= h)
                new_b = h;
        }
        LOG_INFO("node " << node_id << " perform gc new bound " << new_b << " bound " << bound)

        assert((bound <= new_b && new_b - bound <= LOG_BUF_SIZE) || (new_b  < bound && bound - new_b >= LOG_BUF_SIZE));
        for (par_idx_t i = bound; i != new_b ; i = next(i)) {
            //handle spurious failures
            while(!freelist.enqueue(pub[get_idx(i)]));
        }
        bound = new_b;
    }

public:

    LogManager() {
        for (int i =0; i < LOG_BUF_SIZE; i++) {
            while(!freelist.enqueue(&buf[i]));
        }
    }

    Log *get_new_log() {
         Log *log;
         auto ok = freelist.dequeue(log);
         if (!ok) {
             if (gc_mtx.try_lock()) {
                 //check again after locking
                ok = freelist.dequeue(log);
                if (ok) {
                    gc_mtx.unlock();
                    return log;
                }
                perform_gc();
                gc_mtx.unlock();
                ok = freelist.dequeue(log);
                if(!ok)
                    return NULL;
            } else
             return NULL;
         }
         return new(log) Log();
    }

    void produce_tail(Log *l, bool r) {
        l->is_rel = r;
        tail_mtx.lock();
        auto t = tail.load(std::memory_order_acquire);
        pub[get_idx(t)] = l;
        tail.store(next(t),std::memory_order_release);
        tail_mtx.unlock();
    }

    std::mutex &get_head_mutex(unsigned nid) {
        return head_mtxs[nid];
    }

    //only allows exclusive access 
    Log *take_head(unsigned bnid, unsigned nid) {
        //return head, check if overlaps with tail
        auto h = heads[nid].load(std::memory_order_acquire);
        auto t = tail.load(std::memory_order_relaxed);
        if (h == t)
            return NULL;
        auto log = pub[get_idx(h)];
        return log;
    }

    //only allows exclusive access 
    void consume_head(unsigned nid) {
        //move head
        auto h = heads[nid].load(std::memory_order_acquire);
        heads[nid].store(next(h), std::memory_order_release);
    }
};

#endif
